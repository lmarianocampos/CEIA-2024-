{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TDWOgpJWKQa"
   },
   "source": [
    "## Estructura del código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yEV8WbiWl6k",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "teF9O9JJmG7Z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import det, inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sDBLvbTtlwzs"
   },
   "outputs": [],
   "source": [
    "class ClassEncoder:\n",
    "  def fit(self, y):\n",
    "    self.names = np.unique(y)\n",
    "    self.name_to_class = {name:idx for idx, name in enumerate(self.names)}\n",
    "    self.fmt = y.dtype\n",
    "    # Q1: por que no hace falta definir un class_to_name para el mapeo inverso?\n",
    "\n",
    "  def _map_reshape(self, f, arr):\n",
    "    return np.array([f(elem) for elem in arr.flatten()]).reshape(arr.shape)\n",
    "    # Q2: por que hace falta un reshape?\n",
    "\n",
    "  def transform(self, y):\n",
    "    return self._map_reshape(lambda name: self.name_to_class[name], y)\n",
    "\n",
    "  def fit_transform(self, y):\n",
    "    self.fit(y)\n",
    "    return self.transform(y)\n",
    "\n",
    "  def detransform(self, y_hat):\n",
    "    return self._map_reshape(lambda idx: self.names[idx], y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "m0KYC8_uSOu4"
   },
   "outputs": [],
   "source": [
    "class BaseBayesianClassifier:\n",
    "  def __init__(self):\n",
    "    self.encoder = ClassEncoder()\n",
    "\n",
    "  def _estimate_a_priori(self, y):\n",
    "    a_priori = np.bincount(y.flatten().astype(int)) / y.size\n",
    "    # Q3: para que sirve bincount?\n",
    "    return np.log(a_priori)\n",
    "\n",
    "  def _fit_params(self, X, y):\n",
    "    # estimate all needed parameters for given model\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
    "    # this should depend on the model used\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def fit(self, X, y, a_priori=None):\n",
    "    # first encode the classes\n",
    "    y = self.encoder.fit_transform(y)\n",
    "\n",
    "    # if it's needed, estimate a priori probabilities\n",
    "    self.log_a_priori = self._estimate_a_priori(y) if a_priori is None else np.log(a_priori)\n",
    "\n",
    "    # check that a_priori has the correct number of classes\n",
    "    assert len(self.log_a_priori) == len(self.encoder.names), \"A priori probabilities do not match number of classes\"\n",
    "\n",
    "    # now that everything else is in place, estimate all needed parameters for given model\n",
    "    self._fit_params(X, y)\n",
    "    # Q4: por que el _fit_params va al final? no se puede mover a, por ejemplo, antes de la priori?\n",
    "\n",
    "  def predict(self, X):\n",
    "    # this is actually an individual prediction encased in a for-loop\n",
    "    m_obs = X.shape[1]\n",
    "    y_hat = np.empty(m_obs, dtype=self.encoder.fmt)\n",
    "\n",
    "    for i in range(m_obs):\n",
    "      encoded_y_hat_i = self._predict_one(X[:,i].reshape(-1,1))\n",
    "      y_hat[i] = self.encoder.names[encoded_y_hat_i]\n",
    "\n",
    "    # return prediction as a row vector (matching y)\n",
    "    return y_hat.reshape(1,-1)\n",
    "\n",
    "  def _predict_one(self, x):\n",
    "    # calculate all log posteriori probabilities (actually, +C)\n",
    "    log_posteriori = [ log_a_priori_i + self._predict_log_conditional(x, idx) for idx, log_a_priori_i\n",
    "                  in enumerate(self.log_a_priori) ]\n",
    "\n",
    "    # return the class that has maximum a posteriori probability\n",
    "    return np.argmax(log_posteriori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IRamFdiGDuSR"
   },
   "outputs": [],
   "source": [
    "class QDA(BaseBayesianClassifier):\n",
    "\n",
    "  def _fit_params(self, X, y):\n",
    "    # estimate each covariance matrix\n",
    "    self.inv_covs = [inv(np.cov(X[:,y.flatten()==idx], bias=True))\n",
    "                      for idx in range(len(self.log_a_priori))]\n",
    "    # Q5: por que hace falta el flatten y no se puede directamente X[:,y==idx]?\n",
    "    # Q6: por que se usa bias=True en vez del default bias=False?\n",
    "    self.means = [X[:,y.flatten()==idx].mean(axis=1, keepdims=True)\n",
    "                  for idx in range(len(self.log_a_priori))]\n",
    "    # Q7: que hace axis=1? por que no axis=0?\n",
    "\n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
    "    # this should depend on the model used\n",
    "    inv_cov = self.inv_covs[class_idx]\n",
    "    unbiased_x =  x - self.means[class_idx]\n",
    "    return 0.5*np.log(det(inv_cov)) -0.5 * unbiased_x.T @ inv_cov @ unbiased_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fRtC9HEkO5Hu"
   },
   "outputs": [],
   "source": [
    "class TensorizedQDA(QDA):\n",
    "\n",
    "    def _fit_params(self, X, y):\n",
    "        # ask plain QDA to fit params\n",
    "        super()._fit_params(X,y)\n",
    "\n",
    "        # stack onto new dimension\n",
    "        self.tensor_inv_cov = np.stack(self.inv_covs)\n",
    "        self.tensor_means = np.stack(self.means)\n",
    "\n",
    "    def _predict_log_conditionals(self,x):\n",
    "        unbiased_x = x - self.tensor_means\n",
    "        inner_prod = unbiased_x.transpose(0,2,1) @ self.tensor_inv_cov @ unbiased_x\n",
    "\n",
    "        return 0.5*np.log(det(self.tensor_inv_cov)) - 0.5 * inner_prod.flatten()\n",
    "\n",
    "    def _predict_one(self, x):\n",
    "        # return the class that has maximum a posteriori probability\n",
    "        return np.argmax(self.log_a_priori + self._predict_log_conditionals(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS_zoK-gWkRf"
   },
   "source": [
    "## Código para pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nz19b6NJed2A"
   },
   "source": [
    "Seteamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m05KrhUDINVs"
   },
   "outputs": [],
   "source": [
    "# hiperparámetros\n",
    "rng_seed = 6543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hkXcoldXOqs",
    "outputId": "2ce8d627-3433-4bdd-d370-85f6b703a7b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (150, 4), Y:(150, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, fetch_openml\n",
    "\n",
    "def get_iris_dataset():\n",
    "  data = load_iris()\n",
    "  X_full = data.data\n",
    "  y_full = np.array([data.target_names[y] for y in data.target.reshape(-1,1)])\n",
    "  return X_full, y_full\n",
    "\n",
    "def get_penguins():\n",
    "    # get data\n",
    "    df, tgt = fetch_openml(name=\"penguins\", return_X_y=True, as_frame=True, parser='auto')\n",
    "\n",
    "    # drop non-numeric columns\n",
    "    df.drop(columns=[\"island\",\"sex\"], inplace=True)\n",
    "\n",
    "    # drop rows with missing values\n",
    "    mask = df.isna().sum(axis=1) == 0\n",
    "    df = df[mask]\n",
    "    tgt = tgt[mask]\n",
    "\n",
    "    return df.values, tgt.to_numpy().reshape(-1,1)\n",
    "\n",
    "# showing for iris\n",
    "X_full, y_full = get_iris_dataset()\n",
    "\n",
    "print(f\"X: {X_full.shape}, Y:{y_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAk-UQCjKecT",
    "outputId": "9566d67a-b78b-4809-bb94-8f605b065db6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek data matrix\n",
    "X_full[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdzMURX2KVdO",
    "outputId": "af5fc3ac-b391-4769-de47-44cea4f566c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['setosa'],\n",
       "       ['setosa'],\n",
       "       ['setosa'],\n",
       "       ['setosa'],\n",
       "       ['setosa']], dtype='<U10')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek target vector\n",
    "y_full[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl8UFh1OegbJ"
   },
   "source": [
    "Separamos el dataset en train y test para medir performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKP_QmWCIECs",
    "outputId": "07798c6a-aa54-430e-d46d-becc2a4315ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 90) (1, 90) (4, 60) (1, 60)\n"
     ]
    }
   ],
   "source": [
    "# preparing data, train - test validation\n",
    "# 70-30 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_transpose(X, y, test_sz, random_state):\n",
    "    # split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=random_state)\n",
    "\n",
    "    # transpose so observations are column vectors\n",
    "    return X_train.T, y_train.T, X_test.T, y_test.T\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  return (y_true == y_pred).mean()\n",
    "\n",
    "train_x, train_y, test_x, test_y = split_transpose(X_full, y_full, 0.4, rng_seed)\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwgXFPbJemb_"
   },
   "source": [
    "Entrenamos un QDA y medimos su accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dGIf2TA5SpoT"
   },
   "outputs": [],
   "source": [
    "qda = QDA()\n",
    "\n",
    "qda.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0Q30DyLWpTL",
    "outputId": "dbccae86-840c-412f-ed97-22cfac21238a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (apparent) error is 0.0111 while test error is 0.0167\n"
     ]
    }
   ],
   "source": [
    "train_acc = accuracy(train_y, qda.predict(train_x))\n",
    "test_acc = accuracy(test_y, qda.predict(test_x))\n",
    "print(f\"Train (apparent) error is {1-train_acc:.4f} while test error is {1-test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QcLtNNIevC_"
   },
   "source": [
    "Con el magic %%timeit podemos estimar el tiempo que tarda en correr una celda en base a varias ejecuciones. Por poner un ejemplo, acá vamos a estimar lo que tarda un ciclo completo de QDA y también su inferencia (predicción).\n",
    "\n",
    "Ojo! a veces [puede ser necesario ejecutarlo varias veces](https://stackoverflow.com/questions/10994405/python-timeit-results-cached-instead-of-calculated) para obtener resultados consistentes.\n",
    "\n",
    "Si quieren explorar otros métodos de medición también es válido!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnZT-HN2fUuW",
    "outputId": "2618e7c1-7a77-4285-bafb-c2880ad167a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.8 ms ± 3.77 ms per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "qda.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjFbVSqfeHUX",
    "outputId": "0254a727-a1d5-4be3-b73a-2f55d2c84a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.1 ms ± 4.16 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "model = QDA()\n",
    "model.fit(train_x, train_y)\n",
    "model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Implementación base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribucion uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargo el dataset iris\n",
    "X_iris, y_iris = get_iris_dataset()\n",
    "\n",
    "#Separo en test de entrenamiento y test de evaluacio\n",
    "train_x_iris, train_y_iris, test_x_iris, test_y_iris = split_transpose(X_iris, y_iris, 0.4, rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creo el modelo\n",
    "qda_uniform = QDA()\n",
    "\n",
    "#La probabilidad a priori es un array de largo 3 porque CLass encoder toma los y unicos, \n",
    "#en este caso son 3\n",
    "qda_uniform.fit(train_x_iris, train_y_iris, a_priori = [1/3, 1/3, 1/3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (apparent) error is 0.0222 while test error is 0.0167\n"
     ]
    }
   ],
   "source": [
    "#Mido prescicion del modelo\n",
    "train_acc_qda_uniform = accuracy(train_y_iris, qda_uniform.predict(train_x_iris))\n",
    "test_acc_qda_uniform = accuracy(test_y_iris, qda_uniform.predict(test_x_iris))\n",
    "print(f\"Train (apparent) error is {1-train_acc_qda_uniform:.4f} while test error is {1-test_acc_qda_uniform:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Probabilidad 0.9, 0.05, 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo nuevo modelo\n",
    "qda_prob = QDA()\n",
    "\n",
    "qda_prob.fit(train_x_iris, train_y_iris, a_priori = [0.9, 0.05, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (apparent) error is 0.0222 while test error is 0.0167\n"
     ]
    }
   ],
   "source": [
    "#Mido prescicion del modelo\n",
    "train_acc_qda_prob = accuracy(train_y_iris, qda_prob.predict(train_x_iris))\n",
    "test_acc_qda_prob = accuracy(test_y_iris, qda_prob.predict(test_x_iris))\n",
    "print(f\"Train (apparent) error is {1-train_acc_qda_prob:.4f} while test error is {1-test_acc_qda_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambio de orden las probabilidades\n",
    "qda_prob.fit(train_x_iris, train_y_iris, a_priori = [0.05, 0.9, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (apparent) error is 0.0333 while test error is 0.0000\n"
     ]
    }
   ],
   "source": [
    "#Mido prescicion del modelo\n",
    "train_acc_qda_prob = accuracy(train_y_iris, qda_prob.predict(train_x_iris))\n",
    "test_acc_qda_prob = accuracy(test_y_iris, qda_prob.predict(test_x_iris))\n",
    "print(f\"Train (apparent) error is {1-train_acc_qda_prob:.4f} while test error is {1-test_acc_qda_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambio de orden las probabilidades\n",
    "qda_prob.fit(train_x_iris, train_y_iris, a_priori = [0.05, 0.05, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (apparent) error is 0.0333 while test error is 0.0500\n"
     ]
    }
   ],
   "source": [
    "#Mido prescicion del modelo\n",
    "train_acc_qda_prob = accuracy(train_y_iris, qda_prob.predict(train_x_iris))\n",
    "test_acc_qda_prob = accuracy(test_y_iris, qda_prob.predict(test_x_iris))\n",
    "print(f\"Train (apparent) error is {1-train_acc_qda_prob:.4f} while test error is {1-test_acc_qda_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Ver como responder la pregunta. En base a que quiere coomparar si es entre estas dos distribuciones o con la que el hace antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
